{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A Convolutional Network implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import utils as ut\n",
    "import csv\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "featuresDir = './data/SampleFoodClassifier_Norm_100'\n",
    "\n",
    "with open('./sample_food_no_food.csv') as f:\n",
    "    food_no_food = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    \n",
    "\n",
    "data_ids = [element['id'] for element in food_no_food]\n",
    "\n",
    "labels = [int(element['is_food']) for element in food_no_food]\n",
    "#data = [rgb2gray(np.array(Image.open(path.join(featuresDir, element)))) for element in data_ids]\n",
    "data = [np.array(Image.open(path.join(featuresDir, element))) for element in data_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size used for class 0: 6\n",
      "Training size used for class 1: 24\n",
      "Width, Height and channels: 100 100 3\n"
     ]
    }
   ],
   "source": [
    "# Split training data in a train set and a test set. The test set will containt 20% of the total\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(data, labels, test_size=.25, random_state=6)\n",
    "\n",
    "# Parameters\n",
    "#learning_rate = 0.001\n",
    "learning_rate_start= .001\n",
    "training_size = 30\n",
    "training_split= 0.8 #split into training_split 1 and (1-training_split) 0\n",
    "training_iters = 5\n",
    "\n",
    "training_size_1=int(np.floor(training_split*training_size))\n",
    "training_size_0=int(training_size-training_size_1)\n",
    "\n",
    "print \"Training size used for class 0:\", training_size_0\n",
    "print \"Training size used for class 1:\", training_size_1\n",
    "\n",
    "# Network Parameters\n",
    "w, h, channels = data[0].shape\n",
    "print \"Width, Height and channels:\", w, h, channels\n",
    "n_classes = len(set(y_train))\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# print 'Input vector size', n_input, 'train shape', np.array(x_train).shape , 'number of classes', n_classes\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, w, h, channels])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print \"PLEASE MODIFY WD1 TO\", conv2.get_shape().as_list()[1], \"*\",conv2.get_shape().as_list()[2], \"*64\"\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLEASE MODIFY WD1 TO 25 * 25 *64\n"
     ]
    }
   ],
   "source": [
    "# Store layers weight & bias\n",
    "sdev= 0.01\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.truncated_normal([5, 5, channels, 32], stddev=sdev)),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=sdev)),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.truncated_normal([25*25*64, 1024], stddev=sdev)),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.truncated_normal([1024, n_classes], stddev=sdev))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.truncated_normal([32], stddev=sdev)),\n",
    "    'bc2': tf.Variable(tf.truncated_normal([64], stddev=sdev)),\n",
    "    'bd1': tf.Variable(tf.truncated_normal([1024], stddev=sdev)),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_classes], stddev=sdev))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "\n",
    "# optimizer without adapted learning_rate\n",
    "#optimizer = tf.train.AdamOptimizerOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "#optimizer with adapted learning_rate\n",
    "step = tf.Variable(0, trainable=False)\n",
    "rate = tf.train.exponential_decay(learning_rate_start, step, 1, 0.9999)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(rate).minimize(cost, global_step=step)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "y_p = tf.argmax(pred, 1)\n",
    "\n",
    "\n",
    "# Gives an array of arrays, where each position represents % of belonging to respective classs. Eg: a[0.34, 0.66] --> class 0 : 34%, class 1: 66%\n",
    "classes = tf.nn.softmax(pred)\n",
    "\n",
    "\n",
    "def label_class(x):\n",
    "    for i in range(0,len(x)):\n",
    "        print i, \":\", x[i]\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_temp = []\n",
    "\n",
    "for element in y_train:\n",
    "    temp = [0]*len(set(y_train))\n",
    "    temp[element] = 1\n",
    "    y_train_temp.append(temp)\n",
    "    \n",
    "y_train = np.reshape(y_train_temp,(len(y_train_temp), -1))\n",
    "\n",
    "y_test_temp = []\n",
    "\n",
    "for element in y_test:\n",
    "    temp = [0]*len(set(y_test))\n",
    "    temp[element] = 1\n",
    "    y_test_temp.append(temp)\n",
    "    \n",
    "y_test = np.reshape(y_test_temp,(len(y_test_temp), -1))\n",
    "\n",
    "# Proportional sampling from both classes, get features for 0 and 1 each\n",
    "y_help=np.array([el[1] for el in y_train])\n",
    "y_index_0 = np.where(y_help==0)[0]\n",
    "y_index_1 = np.where(y_help==1)[0]\n",
    "\n",
    "x_0 = [x_train[index] for index in y_index_0]\n",
    "x_1 = [x_train[index] for index in y_index_1]\n",
    "\n",
    "#y batch looks always the same for if using proportional sampling\n",
    "iy= np.vstack(([[1,0]]*training_size_0,[[0,1]]*training_size_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss= 50.314503, Training Accuracy= 0.80000\n",
      "Iter 1, Minibatch Loss= 1.062663, Training Accuracy= 0.83333\n",
      "Iter 2, Minibatch Loss= 12.905790, Training Accuracy= 0.20000\n",
      "Iter 3, Minibatch Loss= 2.619724, Training Accuracy= 0.20000\n",
      "Iter 4, Minibatch Loss= 0.628211, Training Accuracy= 0.80000\n",
      "Optimization Finished!\n",
      "Partial testing accuracy: 1.0\n",
      "Partial testing accuracy: 0.949999988079\n",
      "Partial testing accuracy: 0.833333333333\n",
      "Partial testing accuracy: 0.82500000298\n",
      "Partial testing accuracy: 0.860000002384\n",
      "Partial testing accuracy: 0.833333333333\n",
      "Partial testing accuracy: 0.828571430274\n",
      "Partial testing accuracy: 0.80000000447\n",
      "Partial testing accuracy: 0.800000005298\n",
      "Partial testing accuracy: 0.810000002384\n",
      "Partial testing accuracy: 0.82727272944\n",
      "Partial testing accuracy: 0.81666666766\n",
      "Partial testing accuracy: 0.807692307692\n",
      "Partial testing accuracy: 0.821428571429\n",
      "Partial testing accuracy: 0.820000000795\n",
      "Partial testing accuracy: 0.81875000149\n",
      "Partial testing accuracy: 0.817647060927\n",
      "Partial testing accuracy: 0.805555558867\n",
      "Partial testing accuracy: 0.810526317672\n",
      "Partial testing accuracy: 0.820000001788\n",
      "Partial testing accuracy: 0.823809524377\n",
      "Partial testing accuracy: 0.818181818182\n",
      "Partial testing accuracy: 0.817391304866\n",
      "Partial testing accuracy: 0.820833332837\n",
      "Partial testing accuracy: 0.82\n",
      "Partial testing accuracy: 0.819230769689\n",
      "Partial testing accuracy: 0.822222221781\n",
      "Partial testing accuracy: 0.817857142006\n",
      "Partial testing accuracy: 0.820689653528\n",
      "Partial testing accuracy: 0.809999998411\n",
      "Partial testing accuracy: 0.80645161098\n",
      "Partial testing accuracy: 0.809374997392\n",
      "Partial testing accuracy: 0.809090906923\n",
      "Validation accuracy: 0.809090906923\n",
      "Precision for each class:\n",
      "0 : 0.0\n",
      "1 : 0.809230769231\n",
      "Recall for each class:\n",
      "0 : 0.0\n",
      "1 : 1.0\n",
      "F1_score for each class:\n",
      "0 : 0.0\n",
      "1 : 0.894557823129\n",
      "confusion_matrix\n",
      "[[  0  62]\n",
      " [  0 263]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Keep training until reach max iterations\n",
    "    for epoch in range(training_iters):\n",
    "        # Fit training using batch data\n",
    "        x_batch_0 = ut.shuffle(x_0, n_samples=training_size_0, random_state=epoch)\n",
    "        x_batch_1 = ut.shuffle(x_1, n_samples=training_size_1, random_state=epoch)\n",
    "        ix = x_batch_0+x_batch_1\n",
    "        \n",
    "        #ix = ut.shuffle(x_train, n_samples=training_size, random_state=epoch)\n",
    "        #iy = ut.shuffle(y_train, n_samples=training_size, random_state=epoch)\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={x: ix, y: iy, keep_prob: 1.})\n",
    "        # Compute average loss\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: ix, y: iy, keep_prob: 1.})\n",
    "        # Display logs per epoch step\n",
    "        print \"Iter \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    runs = 0\n",
    "    acc = 0.\n",
    "    y_pred = []\n",
    "    class_pred = []\n",
    "    for i in range(0, len(y_test), 10):\n",
    "        if i+10 < len(y_test):\n",
    "            val_accuracy, y_pred_i, cls = sess.run([accuracy, y_p, classes], feed_dict={x: x_test[i:i+10], y: y_test[i:i+10], keep_prob: 1.})\n",
    "            acc += val_accuracy\n",
    "            y_pred.extend(y_pred_i)\n",
    "            class_pred.extend(cls)\n",
    "        else:\n",
    "            val_accuracy, y_pred_i, cls = sess.run([accuracy, y_p, classes], feed_dict={x: x_test[i:], y: y_test[i:], keep_prob: 1.})\n",
    "            acc += val_accuracy\n",
    "            y_pred.extend(y_pred_i)\n",
    "            class_pred.extend(cls)\n",
    "        runs += 1\n",
    "        print \"Partial testing accuracy:\", acc/runs\n",
    "    \n",
    "    #metrics\n",
    "    print \"Validation accuracy:\", acc/runs\n",
    "    y_true = np.argmax(y_test,1)\n",
    "    print \"Precision for each class:\"\n",
    "    label_class(mt.precision_score(y_true, y_pred, average=None))\n",
    "    print \"Recall for each class:\"\n",
    "    label_class(mt.recall_score(y_true, y_pred, average=None))\n",
    "    print \"F1_score for each class:\"\n",
    "    label_class(mt.f1_score(y_true, y_pred, average=None))\n",
    "    print \"confusion_matrix\"\n",
    "    print mt.confusion_matrix(y_true, y_pred)\n",
    "    fpr, tpr, tresholds = mt.roc_curve(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0 as 1 predicted to be 0 at: 46.893247962 %, predicted to be 1 at:  53.1067490578\n",
      "For 1 as 1 predicted to be 0 at: 45.5796957016 %, predicted to be 1 at:  54.4203102589\n",
      "For 2 as 1 predicted to be 0 at: 45.3116029501 %, predicted to be 1 at:  54.6884000301\n",
      "For 3 as 1 predicted to be 0 at: 41.9941604137 %, predicted to be 1 at:  58.0058395863\n",
      "For 4 as 1 predicted to be 0 at: 44.8121964931 %, predicted to be 1 at:  55.1877975464\n",
      "For 5 as 1 predicted to be 0 at: 46.2605029345 %, predicted to be 1 at:  53.7394940853\n",
      "For 6 as 1 predicted to be 0 at: 47.2345292568 %, predicted to be 1 at:  52.7654707432\n",
      "For 7 as 1 predicted to be 0 at: 42.0678794384 %, predicted to be 1 at:  57.9321265221\n",
      "For 8 as 1 predicted to be 0 at: 44.629278779 %, predicted to be 1 at:  55.3707242012\n",
      "For 9 as 1 predicted to be 0 at: 44.6656912565 %, predicted to be 1 at:  55.3343057632\n",
      "For 10 as 1 predicted to be 0 at: 44.4089502096 %, predicted to be 1 at:  55.5910527706\n",
      "For 11 as 1 predicted to be 0 at: 44.8738396168 %, predicted to be 1 at:  55.1261544228\n",
      "For 12 as 1 predicted to be 0 at: 45.822674036 %, predicted to be 1 at:  54.1773319244\n",
      "For 13 as 1 predicted to be 0 at: 44.6345210075 %, predicted to be 1 at:  55.3654789925\n",
      "For 14 as 1 predicted to be 0 at: 44.7236120701 %, predicted to be 1 at:  55.2763938904\n",
      "For 15 as 1 predicted to be 0 at: 45.9307223558 %, predicted to be 1 at:  54.0692746639\n",
      "For 16 as 1 predicted to be 0 at: 46.1232215166 %, predicted to be 1 at:  53.8767695427\n",
      "For 17 as 0 predicted to be 0 at: 45.7570582628 %, predicted to be 1 at:  54.2429387569\n",
      "For 18 as 1 predicted to be 0 at: 47.8688269854 %, predicted to be 1 at:  52.1311700344\n",
      "For 19 as 1 predicted to be 0 at: 44.8056846857 %, predicted to be 1 at:  55.1943182945\n",
      "For 20 as 1 predicted to be 0 at: 46.1812138557 %, predicted to be 1 at:  53.8187861443\n",
      "For 21 as 0 predicted to be 0 at: 46.6478645802 %, predicted to be 1 at:  53.3521354198\n",
      "For 22 as 1 predicted to be 0 at: 44.1615223885 %, predicted to be 1 at:  55.8384776115\n",
      "For 23 as 1 predicted to be 0 at: 43.8955515623 %, predicted to be 1 at:  56.1044454575\n",
      "For 24 as 0 predicted to be 0 at: 45.8046883345 %, predicted to be 1 at:  54.1953086853\n",
      "For 25 as 0 predicted to be 0 at: 42.0174539089 %, predicted to be 1 at:  57.9825520515\n",
      "For 26 as 1 predicted to be 0 at: 46.9620257616 %, predicted to be 1 at:  53.0379772186\n",
      "For 27 as 1 predicted to be 0 at: 44.7955965996 %, predicted to be 1 at:  55.2044093609\n",
      "For 28 as 1 predicted to be 0 at: 42.6310658455 %, predicted to be 1 at:  57.3689341545\n",
      "For 29 as 0 predicted to be 0 at: 47.2736418247 %, predicted to be 1 at:  52.7263641357\n",
      "For 30 as 1 predicted to be 0 at: 44.0839588642 %, predicted to be 1 at:  55.9160470963\n",
      "For 31 as 1 predicted to be 0 at: 46.2203085423 %, predicted to be 1 at:  53.7796914577\n",
      "For 32 as 1 predicted to be 0 at: 39.6278083324 %, predicted to be 1 at:  60.3721916676\n",
      "For 33 as 1 predicted to be 0 at: 40.8312380314 %, predicted to be 1 at:  59.1687560081\n",
      "For 34 as 0 predicted to be 0 at: 46.688246727 %, predicted to be 1 at:  53.311753273\n",
      "For 35 as 0 predicted to be 0 at: 43.4765219688 %, predicted to be 1 at:  56.5234720707\n",
      "For 36 as 1 predicted to be 0 at: 44.4824516773 %, predicted to be 1 at:  55.5175483227\n",
      "For 37 as 1 predicted to be 0 at: 43.8222378492 %, predicted to be 1 at:  56.177765131\n",
      "For 38 as 1 predicted to be 0 at: 44.820535183 %, predicted to be 1 at:  55.179464817\n",
      "For 39 as 1 predicted to be 0 at: 45.9035426378 %, predicted to be 1 at:  54.0964603424\n",
      "For 40 as 1 predicted to be 0 at: 44.0184146166 %, predicted to be 1 at:  55.9815883636\n",
      "For 41 as 1 predicted to be 0 at: 43.5741603374 %, predicted to be 1 at:  56.425845623\n",
      "For 42 as 1 predicted to be 0 at: 45.731779933 %, predicted to be 1 at:  54.2682230473\n",
      "For 43 as 1 predicted to be 0 at: 45.478233695 %, predicted to be 1 at:  54.5217692852\n",
      "For 44 as 1 predicted to be 0 at: 43.7991380692 %, predicted to be 1 at:  56.2008678913\n",
      "For 45 as 1 predicted to be 0 at: 45.6646084785 %, predicted to be 1 at:  54.3353915215\n",
      "For 46 as 1 predicted to be 0 at: 44.2149370909 %, predicted to be 1 at:  55.7850599289\n",
      "For 47 as 1 predicted to be 0 at: 46.9631105661 %, predicted to be 1 at:  53.0368924141\n",
      "For 48 as 1 predicted to be 0 at: 47.7617323399 %, predicted to be 1 at:  52.2382736206\n",
      "For 49 as 1 predicted to be 0 at: 47.0395952463 %, predicted to be 1 at:  52.9604017735\n",
      "For 50 as 1 predicted to be 0 at: 44.7112798691 %, predicted to be 1 at:  55.2887260914\n",
      "For 51 as 1 predicted to be 0 at: 46.7869848013 %, predicted to be 1 at:  53.2130181789\n",
      "For 52 as 1 predicted to be 0 at: 41.5203630924 %, predicted to be 1 at:  58.4796369076\n",
      "For 53 as 1 predicted to be 0 at: 44.7802573442 %, predicted to be 1 at:  55.219745636\n",
      "For 54 as 1 predicted to be 0 at: 47.9347229004 %, predicted to be 1 at:  52.0652711391\n",
      "For 55 as 0 predicted to be 0 at: 48.0959355831 %, predicted to be 1 at:  51.9040644169\n",
      "For 56 as 1 predicted to be 0 at: 45.7115471363 %, predicted to be 1 at:  54.2884528637\n",
      "For 57 as 0 predicted to be 0 at: 45.6712305546 %, predicted to be 1 at:  54.3287694454\n",
      "For 58 as 0 predicted to be 0 at: 47.1930205822 %, predicted to be 1 at:  52.8069853783\n",
      "For 59 as 1 predicted to be 0 at: 45.2588677406 %, predicted to be 1 at:  54.7411322594\n",
      "For 60 as 1 predicted to be 0 at: 45.6257879734 %, predicted to be 1 at:  54.3742120266\n",
      "For 61 as 1 predicted to be 0 at: 45.4557090998 %, predicted to be 1 at:  54.54428792\n",
      "For 62 as 1 predicted to be 0 at: 45.2096283436 %, predicted to be 1 at:  54.790365696\n",
      "For 63 as 0 predicted to be 0 at: 47.1684038639 %, predicted to be 1 at:  52.8315961361\n",
      "For 64 as 0 predicted to be 0 at: 45.4989373684 %, predicted to be 1 at:  54.5010685921\n",
      "For 65 as 1 predicted to be 0 at: 44.0197765827 %, predicted to be 1 at:  55.9802174568\n",
      "For 66 as 1 predicted to be 0 at: 43.7749236822 %, predicted to be 1 at:  56.2250852585\n",
      "For 67 as 1 predicted to be 0 at: 48.1515318155 %, predicted to be 1 at:  51.8484711647\n",
      "For 68 as 1 predicted to be 0 at: 44.870737195 %, predicted to be 1 at:  55.1292657852\n",
      "For 69 as 1 predicted to be 0 at: 44.0006136894 %, predicted to be 1 at:  55.999392271\n",
      "For 70 as 1 predicted to be 0 at: 47.2669482231 %, predicted to be 1 at:  52.7330577374\n",
      "For 71 as 0 predicted to be 0 at: 45.1160043478 %, predicted to be 1 at:  54.883992672\n",
      "For 72 as 1 predicted to be 0 at: 47.0196485519 %, predicted to be 1 at:  52.9803514481\n",
      "For 73 as 0 predicted to be 0 at: 46.7827647924 %, predicted to be 1 at:  53.2172381878\n",
      "For 74 as 1 predicted to be 0 at: 45.0986921787 %, predicted to be 1 at:  54.9013078213\n",
      "For 75 as 1 predicted to be 0 at: 45.2786892653 %, predicted to be 1 at:  54.721313715\n",
      "For 76 as 1 predicted to be 0 at: 47.1253484488 %, predicted to be 1 at:  52.8746545315\n",
      "For 77 as 0 predicted to be 0 at: 43.5037463903 %, predicted to be 1 at:  56.4962565899\n",
      "For 78 as 1 predicted to be 0 at: 44.6175545454 %, predicted to be 1 at:  55.3824484348\n",
      "For 79 as 0 predicted to be 0 at: 46.8911290169 %, predicted to be 1 at:  53.1088709831\n",
      "For 80 as 0 predicted to be 0 at: 47.338706255 %, predicted to be 1 at:  52.661293745\n",
      "For 81 as 1 predicted to be 0 at: 45.0002044439 %, predicted to be 1 at:  54.9997985363\n",
      "For 82 as 1 predicted to be 0 at: 39.5047098398 %, predicted to be 1 at:  60.4952931404\n",
      "For 83 as 1 predicted to be 0 at: 44.9632793665 %, predicted to be 1 at:  55.0367236137\n",
      "For 84 as 1 predicted to be 0 at: 45.4918175936 %, predicted to be 1 at:  54.5081794262\n",
      "For 85 as 1 predicted to be 0 at: 46.1268544197 %, predicted to be 1 at:  53.8731396198\n",
      "For 86 as 1 predicted to be 0 at: 41.5930956602 %, predicted to be 1 at:  58.40690732\n",
      "For 87 as 1 predicted to be 0 at: 46.6808497906 %, predicted to be 1 at:  53.3191561699\n",
      "For 88 as 1 predicted to be 0 at: 40.5420005322 %, predicted to be 1 at:  59.4579994678\n",
      "For 89 as 0 predicted to be 0 at: 43.0376708508 %, predicted to be 1 at:  56.9623231888\n",
      "For 90 as 1 predicted to be 0 at: 43.8149303198 %, predicted to be 1 at:  56.1850726604\n",
      "For 91 as 1 predicted to be 0 at: 45.9978252649 %, predicted to be 1 at:  54.0021717548\n",
      "For 92 as 1 predicted to be 0 at: 47.1336811781 %, predicted to be 1 at:  52.8663218021\n",
      "For 93 as 1 predicted to be 0 at: 44.5198625326 %, predicted to be 1 at:  55.4801404476\n",
      "For 94 as 1 predicted to be 0 at: 44.5923417807 %, predicted to be 1 at:  55.4076552391\n",
      "For 95 as 1 predicted to be 0 at: 45.5205708742 %, predicted to be 1 at:  54.4794261456\n",
      "For 96 as 1 predicted to be 0 at: 46.3902056217 %, predicted to be 1 at:  53.6097943783\n",
      "For 97 as 1 predicted to be 0 at: 45.9854185581 %, predicted to be 1 at:  54.0145814419\n",
      "For 98 as 1 predicted to be 0 at: 45.6186026335 %, predicted to be 1 at:  54.3814003468\n",
      "For 99 as 0 predicted to be 0 at: 45.0715690851 %, predicted to be 1 at:  54.9284338951\n",
      "For 100 as 1 predicted to be 0 at: 46.4653640985 %, predicted to be 1 at:  53.5346329212\n",
      "For 101 as 1 predicted to be 0 at: 46.526029706 %, predicted to be 1 at:  53.4739673138\n",
      "For 102 as 1 predicted to be 0 at: 45.5642938614 %, predicted to be 1 at:  54.4357061386\n",
      "For 103 as 1 predicted to be 0 at: 45.5474704504 %, predicted to be 1 at:  54.4525265694\n",
      "For 104 as 1 predicted to be 0 at: 44.3909615278 %, predicted to be 1 at:  55.6090295315\n",
      "For 105 as 1 predicted to be 0 at: 42.9327726364 %, predicted to be 1 at:  57.0672273636\n",
      "For 106 as 1 predicted to be 0 at: 46.3863611221 %, predicted to be 1 at:  53.6136388779\n",
      "For 107 as 1 predicted to be 0 at: 44.0352022648 %, predicted to be 1 at:  55.9647977352\n",
      "For 108 as 1 predicted to be 0 at: 46.8082040548 %, predicted to be 1 at:  53.1917870045\n",
      "For 109 as 1 predicted to be 0 at: 44.3933755159 %, predicted to be 1 at:  55.6066215038\n",
      "For 110 as 1 predicted to be 0 at: 45.1043516397 %, predicted to be 1 at:  54.8956513405\n",
      "For 111 as 1 predicted to be 0 at: 41.6596293449 %, predicted to be 1 at:  58.3403646946\n",
      "For 112 as 0 predicted to be 0 at: 47.5107848644 %, predicted to be 1 at:  52.4892151356\n",
      "For 113 as 1 predicted to be 0 at: 46.1326092482 %, predicted to be 1 at:  53.8673877716\n",
      "For 114 as 0 predicted to be 0 at: 45.6338822842 %, predicted to be 1 at:  54.3661177158\n",
      "For 115 as 1 predicted to be 0 at: 47.8274524212 %, predicted to be 1 at:  52.1725475788\n",
      "For 116 as 0 predicted to be 0 at: 45.9167033434 %, predicted to be 1 at:  54.0833055973\n",
      "For 117 as 1 predicted to be 0 at: 43.0922269821 %, predicted to be 1 at:  56.9077670574\n",
      "For 118 as 1 predicted to be 0 at: 44.3720877171 %, predicted to be 1 at:  55.6279063225\n",
      "For 119 as 1 predicted to be 0 at: 47.0079511404 %, predicted to be 1 at:  52.9920458794\n",
      "For 120 as 1 predicted to be 0 at: 43.4278786182 %, predicted to be 1 at:  56.5721213818\n",
      "For 121 as 0 predicted to be 0 at: 45.1355695724 %, predicted to be 1 at:  54.8644304276\n",
      "For 122 as 1 predicted to be 0 at: 47.6073116064 %, predicted to be 1 at:  52.3926973343\n",
      "For 123 as 1 predicted to be 0 at: 43.9588159323 %, predicted to be 1 at:  56.041187048\n",
      "For 124 as 1 predicted to be 0 at: 42.3895925283 %, predicted to be 1 at:  57.6104044914\n",
      "For 125 as 0 predicted to be 0 at: 44.6454644203 %, predicted to be 1 at:  55.3545355797\n",
      "For 126 as 0 predicted to be 0 at: 44.7836875916 %, predicted to be 1 at:  55.2163124084\n",
      "For 127 as 1 predicted to be 0 at: 45.5637514591 %, predicted to be 1 at:  54.4362485409\n",
      "For 128 as 1 predicted to be 0 at: 46.8974679708 %, predicted to be 1 at:  53.1025290489\n",
      "For 129 as 1 predicted to be 0 at: 45.8882749081 %, predicted to be 1 at:  54.1117250919\n",
      "For 130 as 1 predicted to be 0 at: 43.8564091921 %, predicted to be 1 at:  56.1435878277\n",
      "For 131 as 1 predicted to be 0 at: 46.0928797722 %, predicted to be 1 at:  53.9071142673\n",
      "For 132 as 1 predicted to be 0 at: 45.7843393087 %, predicted to be 1 at:  54.215657711\n",
      "For 133 as 1 predicted to be 0 at: 41.7957246304 %, predicted to be 1 at:  58.2042813301\n",
      "For 134 as 1 predicted to be 0 at: 43.5322970152 %, predicted to be 1 at:  56.4677000046\n",
      "For 135 as 1 predicted to be 0 at: 47.3844259977 %, predicted to be 1 at:  52.615571022\n",
      "For 136 as 1 predicted to be 0 at: 45.9263414145 %, predicted to be 1 at:  54.0736556053\n",
      "For 137 as 1 predicted to be 0 at: 45.4273402691 %, predicted to be 1 at:  54.5726656914\n",
      "For 138 as 1 predicted to be 0 at: 43.7914788723 %, predicted to be 1 at:  56.2085211277\n",
      "For 139 as 1 predicted to be 0 at: 47.4740475416 %, predicted to be 1 at:  52.5259554386\n",
      "For 140 as 1 predicted to be 0 at: 46.8514770269 %, predicted to be 1 at:  53.1485259533\n",
      "For 141 as 1 predicted to be 0 at: 44.6370512247 %, predicted to be 1 at:  55.3629517555\n",
      "For 142 as 0 predicted to be 0 at: 43.6581194401 %, predicted to be 1 at:  56.3418805599\n",
      "For 143 as 1 predicted to be 0 at: 44.4490373135 %, predicted to be 1 at:  55.5509626865\n",
      "For 144 as 1 predicted to be 0 at: 42.7218556404 %, predicted to be 1 at:  57.2781383991\n",
      "For 145 as 0 predicted to be 0 at: 46.9653695822 %, predicted to be 1 at:  53.0346333981\n",
      "For 146 as 1 predicted to be 0 at: 42.6912009716 %, predicted to be 1 at:  57.3088049889\n",
      "For 147 as 1 predicted to be 0 at: 44.5366829634 %, predicted to be 1 at:  55.4633140564\n",
      "For 148 as 1 predicted to be 0 at: 43.5133695602 %, predicted to be 1 at:  56.4866364002\n",
      "For 149 as 1 predicted to be 0 at: 44.8740661144 %, predicted to be 1 at:  55.1259338856\n",
      "For 150 as 0 predicted to be 0 at: 43.4837907553 %, predicted to be 1 at:  56.516212225\n",
      "For 151 as 1 predicted to be 0 at: 37.6968294382 %, predicted to be 1 at:  62.303173542\n",
      "For 152 as 1 predicted to be 0 at: 45.5155342817 %, predicted to be 1 at:  54.484474659\n",
      "For 153 as 1 predicted to be 0 at: 46.4534461498 %, predicted to be 1 at:  53.5465478897\n",
      "For 154 as 1 predicted to be 0 at: 44.7320908308 %, predicted to be 1 at:  55.2679121494\n",
      "For 155 as 1 predicted to be 0 at: 44.8737591505 %, predicted to be 1 at:  55.1262438297\n",
      "For 156 as 1 predicted to be 0 at: 46.6351300478 %, predicted to be 1 at:  53.3648729324\n",
      "For 157 as 0 predicted to be 0 at: 48.3941584826 %, predicted to be 1 at:  51.6058444977\n",
      "For 158 as 1 predicted to be 0 at: 45.9120452404 %, predicted to be 1 at:  54.0879547596\n",
      "For 159 as 1 predicted to be 0 at: 46.8229681253 %, predicted to be 1 at:  53.1770288944\n",
      "For 160 as 1 predicted to be 0 at: 43.2726234198 %, predicted to be 1 at:  56.7273795605\n",
      "For 161 as 0 predicted to be 0 at: 44.8977142572 %, predicted to be 1 at:  55.1022827625\n",
      "For 162 as 1 predicted to be 0 at: 45.4426079988 %, predicted to be 1 at:  54.5573890209\n",
      "For 163 as 1 predicted to be 0 at: 45.3754991293 %, predicted to be 1 at:  54.6245098114\n",
      "For 164 as 1 predicted to be 0 at: 45.8715230227 %, predicted to be 1 at:  54.1284799576\n",
      "For 165 as 1 predicted to be 0 at: 46.0699617863 %, predicted to be 1 at:  53.9300382137\n",
      "For 166 as 0 predicted to be 0 at: 44.9779629707 %, predicted to be 1 at:  55.0220370293\n",
      "For 167 as 1 predicted to be 0 at: 44.3260014057 %, predicted to be 1 at:  55.6739985943\n",
      "For 168 as 1 predicted to be 0 at: 46.1540132761 %, predicted to be 1 at:  53.8459837437\n",
      "For 169 as 1 predicted to be 0 at: 40.2976661921 %, predicted to be 1 at:  59.7023367882\n",
      "For 170 as 1 predicted to be 0 at: 43.7003701925 %, predicted to be 1 at:  56.2996327877\n",
      "For 171 as 0 predicted to be 0 at: 42.0415371656 %, predicted to be 1 at:  57.9584598541\n",
      "For 172 as 1 predicted to be 0 at: 47.1652388573 %, predicted to be 1 at:  52.8347611427\n",
      "For 173 as 0 predicted to be 0 at: 44.0329194069 %, predicted to be 1 at:  55.9670805931\n",
      "For 174 as 1 predicted to be 0 at: 46.3038355112 %, predicted to be 1 at:  53.6961615086\n",
      "For 175 as 1 predicted to be 0 at: 46.6304033995 %, predicted to be 1 at:  53.3695995808\n",
      "For 176 as 1 predicted to be 0 at: 44.8688536882 %, predicted to be 1 at:  55.1311433315\n",
      "For 177 as 0 predicted to be 0 at: 44.3136662245 %, predicted to be 1 at:  55.6863367558\n",
      "For 178 as 1 predicted to be 0 at: 45.6739574671 %, predicted to be 1 at:  54.3260514736\n",
      "For 179 as 0 predicted to be 0 at: 46.1558908224 %, predicted to be 1 at:  53.8441121578\n",
      "For 180 as 1 predicted to be 0 at: 44.8764950037 %, predicted to be 1 at:  55.1235079765\n",
      "For 181 as 1 predicted to be 0 at: 46.0374951363 %, predicted to be 1 at:  53.9625048637\n",
      "For 182 as 1 predicted to be 0 at: 45.248696208 %, predicted to be 1 at:  54.7513067722\n",
      "For 183 as 1 predicted to be 0 at: 46.1054831743 %, predicted to be 1 at:  53.8945138454\n",
      "For 184 as 1 predicted to be 0 at: 45.6532239914 %, predicted to be 1 at:  54.3467700481\n",
      "For 185 as 1 predicted to be 0 at: 45.3112632036 %, predicted to be 1 at:  54.6887397766\n",
      "For 186 as 0 predicted to be 0 at: 44.1537231207 %, predicted to be 1 at:  55.8462679386\n",
      "For 187 as 1 predicted to be 0 at: 46.7497259378 %, predicted to be 1 at:  53.2502710819\n",
      "For 188 as 1 predicted to be 0 at: 48.0494022369 %, predicted to be 1 at:  51.9506037235\n",
      "For 189 as 1 predicted to be 0 at: 40.8501893282 %, predicted to be 1 at:  59.1498076916\n",
      "For 190 as 1 predicted to be 0 at: 45.872798562 %, predicted to be 1 at:  54.1272044182\n",
      "For 191 as 1 predicted to be 0 at: 43.1911200285 %, predicted to be 1 at:  56.8088769913\n",
      "For 192 as 1 predicted to be 0 at: 46.7808663845 %, predicted to be 1 at:  53.219139576\n",
      "For 193 as 1 predicted to be 0 at: 44.5714235306 %, predicted to be 1 at:  55.4285764694\n",
      "For 194 as 1 predicted to be 0 at: 47.324308753 %, predicted to be 1 at:  52.6757001877\n",
      "For 195 as 1 predicted to be 0 at: 45.2381581068 %, predicted to be 1 at:  54.7618448734\n",
      "For 196 as 1 predicted to be 0 at: 44.6053087711 %, predicted to be 1 at:  55.3946912289\n",
      "For 197 as 1 predicted to be 0 at: 44.7070807219 %, predicted to be 1 at:  55.2929162979\n",
      "For 198 as 1 predicted to be 0 at: 46.0271388292 %, predicted to be 1 at:  53.972864151\n",
      "For 199 as 1 predicted to be 0 at: 45.6030249596 %, predicted to be 1 at:  54.3969750404\n",
      "For 200 as 1 predicted to be 0 at: 45.7703113556 %, predicted to be 1 at:  54.2296946049\n",
      "For 201 as 1 predicted to be 0 at: 45.311152935 %, predicted to be 1 at:  54.688847065\n",
      "For 202 as 1 predicted to be 0 at: 46.609762311 %, predicted to be 1 at:  53.3902287483\n",
      "For 203 as 0 predicted to be 0 at: 45.8457887173 %, predicted to be 1 at:  54.1542112827\n",
      "For 204 as 1 predicted to be 0 at: 43.5591816902 %, predicted to be 1 at:  56.4408183098\n",
      "For 205 as 1 predicted to be 0 at: 45.8039194345 %, predicted to be 1 at:  54.1960775852\n",
      "For 206 as 1 predicted to be 0 at: 45.9736555815 %, predicted to be 1 at:  54.0263473988\n",
      "For 207 as 1 predicted to be 0 at: 39.4369184971 %, predicted to be 1 at:  60.5630874634\n",
      "For 208 as 1 predicted to be 0 at: 45.8789259195 %, predicted to be 1 at:  54.1210711002\n",
      "For 209 as 1 predicted to be 0 at: 46.5995818377 %, predicted to be 1 at:  53.4004211426\n",
      "For 210 as 1 predicted to be 0 at: 42.2362059355 %, predicted to be 1 at:  57.7637910843\n",
      "For 211 as 0 predicted to be 0 at: 44.9916511774 %, predicted to be 1 at:  55.0083577633\n",
      "For 212 as 1 predicted to be 0 at: 45.7708597183 %, predicted to be 1 at:  54.2291402817\n",
      "For 213 as 1 predicted to be 0 at: 43.9729660749 %, predicted to be 1 at:  56.0270309448\n",
      "For 214 as 1 predicted to be 0 at: 44.1122382879 %, predicted to be 1 at:  55.8877646923\n",
      "For 215 as 0 predicted to be 0 at: 46.0029870272 %, predicted to be 1 at:  53.9970099926\n",
      "For 216 as 1 predicted to be 0 at: 48.4920084476 %, predicted to be 1 at:  51.5079915524\n",
      "For 217 as 1 predicted to be 0 at: 40.7688349485 %, predicted to be 1 at:  59.2311680317\n",
      "For 218 as 0 predicted to be 0 at: 45.1831489801 %, predicted to be 1 at:  54.8168480396\n",
      "For 219 as 1 predicted to be 0 at: 44.7202891111 %, predicted to be 1 at:  55.2797079086\n",
      "For 220 as 1 predicted to be 0 at: 47.1954584122 %, predicted to be 1 at:  52.8045415878\n",
      "For 221 as 1 predicted to be 0 at: 43.7450796366 %, predicted to be 1 at:  56.2549233437\n",
      "For 222 as 1 predicted to be 0 at: 42.7227079868 %, predicted to be 1 at:  57.2772920132\n",
      "For 223 as 1 predicted to be 0 at: 42.8472816944 %, predicted to be 1 at:  57.1527183056\n",
      "For 224 as 1 predicted to be 0 at: 46.4557617903 %, predicted to be 1 at:  53.5442352295\n",
      "For 225 as 1 predicted to be 0 at: 47.1484392881 %, predicted to be 1 at:  52.8515577316\n",
      "For 226 as 1 predicted to be 0 at: 49.5263129473 %, predicted to be 1 at:  50.473690033\n",
      "For 227 as 0 predicted to be 0 at: 44.3714410067 %, predicted to be 1 at:  55.6285560131\n",
      "For 228 as 1 predicted to be 0 at: 46.0770577192 %, predicted to be 1 at:  53.922945261\n",
      "For 229 as 0 predicted to be 0 at: 46.1102932692 %, predicted to be 1 at:  53.8897037506\n",
      "For 230 as 1 predicted to be 0 at: 41.5850639343 %, predicted to be 1 at:  58.4149360657\n",
      "For 231 as 1 predicted to be 0 at: 42.8688973188 %, predicted to be 1 at:  57.1310937405\n",
      "For 232 as 1 predicted to be 0 at: 43.9480364323 %, predicted to be 1 at:  56.0519635677\n",
      "For 233 as 1 predicted to be 0 at: 45.2063977718 %, predicted to be 1 at:  54.7936022282\n",
      "For 234 as 1 predicted to be 0 at: 46.235370636 %, predicted to be 1 at:  53.7646234035\n",
      "For 235 as 1 predicted to be 0 at: 42.2952622175 %, predicted to be 1 at:  57.7047348022\n",
      "For 236 as 0 predicted to be 0 at: 38.4738385677 %, predicted to be 1 at:  61.5261673927\n",
      "For 237 as 1 predicted to be 0 at: 44.359728694 %, predicted to be 1 at:  55.6402742863\n",
      "For 238 as 1 predicted to be 0 at: 44.6219682693 %, predicted to be 1 at:  55.3780317307\n",
      "For 239 as 1 predicted to be 0 at: 46.8212962151 %, predicted to be 1 at:  53.1787037849\n",
      "For 240 as 1 predicted to be 0 at: 38.8873517513 %, predicted to be 1 at:  61.1126482487\n",
      "For 241 as 1 predicted to be 0 at: 45.0101166964 %, predicted to be 1 at:  54.9898862839\n",
      "For 242 as 0 predicted to be 0 at: 46.7763870955 %, predicted to be 1 at:  53.2236099243\n",
      "For 243 as 1 predicted to be 0 at: 44.1087275743 %, predicted to be 1 at:  55.8912694454\n",
      "For 244 as 1 predicted to be 0 at: 41.401475668 %, predicted to be 1 at:  58.598524332\n",
      "For 245 as 1 predicted to be 0 at: 40.3842777014 %, predicted to be 1 at:  59.6157193184\n",
      "For 246 as 1 predicted to be 0 at: 45.8258867264 %, predicted to be 1 at:  54.1741132736\n",
      "For 247 as 1 predicted to be 0 at: 45.4971402884 %, predicted to be 1 at:  54.5028567314\n",
      "For 248 as 1 predicted to be 0 at: 43.4993565083 %, predicted to be 1 at:  56.5006375313\n",
      "For 249 as 0 predicted to be 0 at: 46.4456439018 %, predicted to be 1 at:  53.5543501377\n",
      "For 250 as 1 predicted to be 0 at: 46.9271242619 %, predicted to be 1 at:  53.0728757381\n",
      "For 251 as 1 predicted to be 0 at: 45.9764689207 %, predicted to be 1 at:  54.0235340595\n",
      "For 252 as 1 predicted to be 0 at: 42.1718329191 %, predicted to be 1 at:  57.8281700611\n",
      "For 253 as 0 predicted to be 0 at: 47.5897312164 %, predicted to be 1 at:  52.410274744\n",
      "For 254 as 1 predicted to be 0 at: 44.1902667284 %, predicted to be 1 at:  55.8097302914\n",
      "For 255 as 1 predicted to be 0 at: 42.6615715027 %, predicted to be 1 at:  57.3384225368\n",
      "For 256 as 0 predicted to be 0 at: 47.7094352245 %, predicted to be 1 at:  52.2905707359\n",
      "For 257 as 1 predicted to be 0 at: 45.0143158436 %, predicted to be 1 at:  54.9856841564\n",
      "For 258 as 1 predicted to be 0 at: 42.4170315266 %, predicted to be 1 at:  57.5829684734\n",
      "For 259 as 1 predicted to be 0 at: 41.0155385733 %, predicted to be 1 at:  58.984464407\n",
      "For 260 as 1 predicted to be 0 at: 46.0346013308 %, predicted to be 1 at:  53.9654016495\n",
      "For 261 as 1 predicted to be 0 at: 46.3951677084 %, predicted to be 1 at:  53.6048293114\n",
      "For 262 as 1 predicted to be 0 at: 45.2600091696 %, predicted to be 1 at:  54.7399938107\n",
      "For 263 as 0 predicted to be 0 at: 47.8074580431 %, predicted to be 1 at:  52.1925389767\n",
      "For 264 as 1 predicted to be 0 at: 47.0903605223 %, predicted to be 1 at:  52.9096364975\n",
      "For 265 as 1 predicted to be 0 at: 46.0667699575 %, predicted to be 1 at:  53.9332270622\n",
      "For 266 as 1 predicted to be 0 at: 43.8468575478 %, predicted to be 1 at:  56.1531364918\n",
      "For 267 as 1 predicted to be 0 at: 46.6248452663 %, predicted to be 1 at:  53.3751547337\n",
      "For 268 as 1 predicted to be 0 at: 44.1656172276 %, predicted to be 1 at:  55.834376812\n",
      "For 269 as 1 predicted to be 0 at: 47.0058917999 %, predicted to be 1 at:  52.9941082001\n",
      "For 270 as 0 predicted to be 0 at: 46.7728108168 %, predicted to be 1 at:  53.2271921635\n",
      "For 271 as 1 predicted to be 0 at: 47.1656501293 %, predicted to be 1 at:  52.8343558311\n",
      "For 272 as 1 predicted to be 0 at: 44.7524696589 %, predicted to be 1 at:  55.2475273609\n",
      "For 273 as 1 predicted to be 0 at: 43.3902323246 %, predicted to be 1 at:  56.6097676754\n",
      "For 274 as 0 predicted to be 0 at: 47.4626243114 %, predicted to be 1 at:  52.5373756886\n",
      "For 275 as 1 predicted to be 0 at: 45.1603382826 %, predicted to be 1 at:  54.8396587372\n",
      "For 276 as 1 predicted to be 0 at: 43.7142729759 %, predicted to be 1 at:  56.2857270241\n",
      "For 277 as 1 predicted to be 0 at: 43.0972993374 %, predicted to be 1 at:  56.9026947021\n",
      "For 278 as 1 predicted to be 0 at: 43.9651936293 %, predicted to be 1 at:  56.034809351\n",
      "For 279 as 0 predicted to be 0 at: 45.8163499832 %, predicted to be 1 at:  54.1836500168\n",
      "For 280 as 1 predicted to be 0 at: 44.6434050798 %, predicted to be 1 at:  55.3565919399\n",
      "For 281 as 1 predicted to be 0 at: 43.5357660055 %, predicted to be 1 at:  56.4642250538\n",
      "For 282 as 1 predicted to be 0 at: 45.4555958509 %, predicted to be 1 at:  54.5444071293\n",
      "For 283 as 1 predicted to be 0 at: 43.4812158346 %, predicted to be 1 at:  56.5187811852\n",
      "For 284 as 1 predicted to be 0 at: 43.9506441355 %, predicted to be 1 at:  56.0493588448\n",
      "For 285 as 1 predicted to be 0 at: 47.6879477501 %, predicted to be 1 at:  52.3120582104\n",
      "For 286 as 1 predicted to be 0 at: 46.1604893208 %, predicted to be 1 at:  53.8395106792\n",
      "For 287 as 1 predicted to be 0 at: 43.7157928944 %, predicted to be 1 at:  56.2842071056\n",
      "For 288 as 1 predicted to be 0 at: 44.7530090809 %, predicted to be 1 at:  55.2469968796\n",
      "For 289 as 0 predicted to be 0 at: 45.04750669 %, predicted to be 1 at:  54.9524903297\n",
      "For 290 as 1 predicted to be 0 at: 46.2601989508 %, predicted to be 1 at:  53.739798069\n",
      "For 291 as 1 predicted to be 0 at: 47.2725361586 %, predicted to be 1 at:  52.7274668217\n",
      "For 292 as 0 predicted to be 0 at: 46.95712924 %, predicted to be 1 at:  53.0428647995\n",
      "For 293 as 1 predicted to be 0 at: 45.5110549927 %, predicted to be 1 at:  54.4889450073\n",
      "For 294 as 0 predicted to be 0 at: 46.7828094959 %, predicted to be 1 at:  53.2171905041\n",
      "For 295 as 0 predicted to be 0 at: 45.9373682737 %, predicted to be 1 at:  54.062628746\n",
      "For 296 as 0 predicted to be 0 at: 43.1697010994 %, predicted to be 1 at:  56.8302989006\n",
      "For 297 as 0 predicted to be 0 at: 46.707367897 %, predicted to be 1 at:  53.292632103\n",
      "For 298 as 1 predicted to be 0 at: 46.8518525362 %, predicted to be 1 at:  53.1481564045\n",
      "For 299 as 1 predicted to be 0 at: 45.3478008509 %, predicted to be 1 at:  54.6521961689\n",
      "For 300 as 0 predicted to be 0 at: 46.5564996004 %, predicted to be 1 at:  53.4435033798\n",
      "For 301 as 1 predicted to be 0 at: 45.5831617117 %, predicted to be 1 at:  54.416847229\n",
      "For 302 as 0 predicted to be 0 at: 43.8835501671 %, predicted to be 1 at:  56.1164498329\n",
      "For 303 as 0 predicted to be 0 at: 45.4728811979 %, predicted to be 1 at:  54.5271098614\n",
      "For 304 as 1 predicted to be 0 at: 45.8633869886 %, predicted to be 1 at:  54.1366159916\n",
      "For 305 as 1 predicted to be 0 at: 46.1415916681 %, predicted to be 1 at:  53.8584113121\n",
      "For 306 as 1 predicted to be 0 at: 45.6675291061 %, predicted to be 1 at:  54.3324708939\n",
      "For 307 as 1 predicted to be 0 at: 43.5500204563 %, predicted to be 1 at:  56.4499855042\n",
      "For 308 as 1 predicted to be 0 at: 44.1498607397 %, predicted to be 1 at:  55.8501422405\n",
      "For 309 as 1 predicted to be 0 at: 41.9828027487 %, predicted to be 1 at:  58.0172002316\n",
      "For 310 as 0 predicted to be 0 at: 43.6228364706 %, predicted to be 1 at:  56.3771665096\n",
      "For 311 as 1 predicted to be 0 at: 43.0816352367 %, predicted to be 1 at:  56.9183647633\n",
      "For 312 as 1 predicted to be 0 at: 45.1750785112 %, predicted to be 1 at:  54.8249185085\n",
      "For 313 as 1 predicted to be 0 at: 42.6684260368 %, predicted to be 1 at:  57.3315739632\n",
      "For 314 as 1 predicted to be 0 at: 45.1595067978 %, predicted to be 1 at:  54.8404932022\n",
      "For 315 as 1 predicted to be 0 at: 46.4423328638 %, predicted to be 1 at:  53.5576701164\n",
      "For 316 as 1 predicted to be 0 at: 45.1548695564 %, predicted to be 1 at:  54.8451244831\n",
      "For 317 as 1 predicted to be 0 at: 45.3935027122 %, predicted to be 1 at:  54.6064913273\n",
      "For 318 as 1 predicted to be 0 at: 44.8677390814 %, predicted to be 1 at:  55.1322638988\n",
      "For 319 as 1 predicted to be 0 at: 44.5173442364 %, predicted to be 1 at:  55.4826557636\n",
      "For 320 as 1 predicted to be 0 at: 45.6462621689 %, predicted to be 1 at:  54.3537437916\n",
      "For 321 as 1 predicted to be 0 at: 46.31100595 %, predicted to be 1 at:  53.6889851093\n",
      "For 322 as 1 predicted to be 0 at: 46.405351162 %, predicted to be 1 at:  53.5946428776\n",
      "For 323 as 0 predicted to be 0 at: 48.8228648901 %, predicted to be 1 at:  51.1771440506\n",
      "For 324 as 1 predicted to be 0 at: 45.1822042465 %, predicted to be 1 at:  54.8178017139\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print \"For\", i, \"as\", y_test[i][1], \"predicted to be 0 at:\", class_pred[i][0]*100, \"%, predicted to be 1 at: \", class_pred[i][1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
