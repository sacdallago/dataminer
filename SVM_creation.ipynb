{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics, cross_validation, grid_search\n",
    "\n",
    "# Import save and load classifiers utils\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Import data elaboration utils\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "import urllib2\n",
    "from urlparse import urlparse\n",
    "from __future__ import division\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to process RGB images and make them become feature vectors\n",
    "\n",
    "def process_directory(directory):\n",
    "    '''Returns an array of feature vectors for all the image files in a\n",
    "    directory (and all its subdirectories). Symbolic links are ignored.\n",
    "\n",
    "    Args:\n",
    "      directory (str): directory to process.\n",
    "\n",
    "    Returns:\n",
    "      list of list of float: a list of feature vectors.\n",
    "    '''\n",
    "    training = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            img_feature = process_image_file(file_path)\n",
    "            if img_feature:\n",
    "                training.append(img_feature)\n",
    "    return training\n",
    "\n",
    "def process_image_files(files):\n",
    "    '''Returns an array of feature vectors for all the image files in a\n",
    "    directory (and all its subdirectories). Symbolic links are ignored.\n",
    "\n",
    "    Args:\n",
    "      directory (str): directory to process.\n",
    "\n",
    "    Returns:\n",
    "      list of list of float: a list of feature vectors.\n",
    "    '''\n",
    "    training = []\n",
    "    for file_path in files:\n",
    "        img_feature = process_image_file(file_path)\n",
    "        if img_feature:\n",
    "            training.append(img_feature)\n",
    "    return training\n",
    "\n",
    "\n",
    "def process_image_file(image_path):\n",
    "    '''Given an image path it returns its feature vector.\n",
    "\n",
    "    Args:\n",
    "      image_path (str): path of the image file to process.\n",
    "\n",
    "    Returns:\n",
    "      list of float: feature vector on success, None otherwise.\n",
    "    '''\n",
    "    image_fp = StringIO(open(image_path, 'rb').read())\n",
    "    try:\n",
    "        image = Image.open(image_fp)\n",
    "        return process_image(image)\n",
    "    except IOError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_image_url(image_url):\n",
    "    '''Given an image URL it returns its feature vector\n",
    "\n",
    "    Args:\n",
    "      image_url (str): url of the image to process.\n",
    "\n",
    "    Returns:\n",
    "      list of float: feature vector.\n",
    "\n",
    "    Raises:\n",
    "      Any exception raised by urllib2 requests.\n",
    "\n",
    "      IOError: if the URL does not point to a valid file.\n",
    "    '''\n",
    "    parsed_url = urlparse(image_url)\n",
    "    request = urllib2.Request(image_url)\n",
    "    # set a User-Agent and Referer to work around servers that block a typical\n",
    "    # user agents and hotlinking. Sorry, it's for science!\n",
    "    request.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux ' \\\n",
    "            'x86_64; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
    "    request.add_header('Referrer', parsed_url.netloc)\n",
    "    # Wrap network data in StringIO so that it looks like a file\n",
    "    net_data = StringIO(urllib2.build_opener().open(request).read())\n",
    "    image = Image.open(net_data)\n",
    "    return process_image(image)\n",
    "\n",
    "\n",
    "def process_image(image, blocks=6):\n",
    "    '''Given a PIL Image object it returns its feature vector.\n",
    "\n",
    "    Args:\n",
    "      image (PIL.Image): image to process.\n",
    "      blocks (int, optional): number of block to subdivide the RGB space into.\n",
    "\n",
    "    Returns:\n",
    "      list of float: feature vector if successful. None if the image is not\n",
    "      RGB.\n",
    "    '''\n",
    "    if not image.mode == 'RGB':\n",
    "        return None\n",
    "    feature = [0] * blocks * blocks * blocks\n",
    "    pixel_count = 0\n",
    "    for pixel in image.getdata():\n",
    "        ridx = int(pixel[0]/(256/blocks))\n",
    "        gidx = int(pixel[1]/(256/blocks))\n",
    "        bidx = int(pixel[2]/(256/blocks))\n",
    "        idx = ridx + gidx * blocks + bidx * blocks * blocks\n",
    "        feature[idx] += 1\n",
    "        pixel_count += 1\n",
    "    return [x/pixel_count for x in feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "dataDir = './data'\n",
    "photoDir = './data/train_photos'\n",
    "\n",
    "with open('./sample_food_no_food.csv') as f:\n",
    "    food_no_food = [{k: v for k, v in row.items()}\n",
    "        for row in csv.DictReader(f, skipinitialspace=True)]\n",
    "    \n",
    "positive = process_image_files([os.path.join(photoDir, element['id']) for element in food_no_food if element['is_food'] is '1'])\n",
    "negative = process_image_files([os.path.join(photoDir, element['id']) for element in food_no_food if element['is_food'] is '0'])\n",
    "\n",
    "data = negative + positive\n",
    "labels = [0] * len(negative) + [1] * len(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training data in a train set and a test set. The test set will containt 20% of the total\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(data, labels, test_size=0.25, random_state=6)\n",
    "\n",
    "# Define the parameter search space\n",
    "# parameters = {'kernel': ['linear', 'rbf'], 'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]}\n",
    "parameters = {'kernel': ['linear'], 'C': [1000], 'gamma': [0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has positive 753 and negative 222\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "# Search for the best classifier within the search space and return it\n",
    "print 'Train set has positive', len([i for i in y_train if i is 1]), 'and negative', len([i for i in y_train if i is 0])\n",
    "\n",
    "kf = cross_validation.KFold(n=len(x_train), n_folds=20, shuffle=True, random_state=3)\n",
    "ss = cross_validation.ShuffleSplit(n=len(x_train), test_size=0.25, n_iter=10, random_state=3)\n",
    "\n",
    "grid = grid_search.GridSearchCV(svm.SVC(verbose=True), parameters, cv=kf)\n",
    "grid.fit(x_train, y_train)\n",
    "classifier = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters: {'kernel': 'linear', 'C': 1000, 'gamma': 0.01}\n",
      "Test set has positive 255 and negative 70\n",
      "\n",
      "Best classifier score\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   not-food       0.60      0.36      0.45        70\n",
      "       food       0.84      0.93      0.88       255\n",
      "\n",
      "avg / total       0.79      0.81      0.79       325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print\n",
    "print 'Best parameters:', grid.best_params_\n",
    "print 'Test set has positive', len([i for i in y_test if i is 1]), 'and negative', len([i for i in y_test if i is 0])\n",
    "print\n",
    "print 'Best classifier score'\n",
    "print\n",
    "print(metrics.classification_report(y_test, classifier.predict(x_test), target_names=['not-food', 'food']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./foodClassifier/foodClassifier.pkl',\n",
       " './foodClassifier/foodClassifier.pkl_01.npy',\n",
       " './foodClassifier/foodClassifier.pkl_02.npy',\n",
       " './foodClassifier/foodClassifier.pkl_03.npy',\n",
       " './foodClassifier/foodClassifier.pkl_04.npy',\n",
       " './foodClassifier/foodClassifier.pkl_05.npy',\n",
       " './foodClassifier/foodClassifier.pkl_06.npy',\n",
       " './foodClassifier/foodClassifier.pkl_07.npy',\n",
       " './foodClassifier/foodClassifier.pkl_08.npy',\n",
       " './foodClassifier/foodClassifier.pkl_09.npy',\n",
       " './foodClassifier/foodClassifier.pkl_10.npy',\n",
       " './foodClassifier/foodClassifier.pkl_11.npy']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save classifier\n",
    "\n",
    "joblib.dump(classifier, './foodClassifier/foodClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load classifier\n",
    "\n",
    "classifier = joblib.load('./foodClassifier/foodClassifier.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict classes for all images in the data folder\n",
    "\n",
    "picturesFolder = './data/train_photos'\n",
    "\n",
    "onAll = False\n",
    "howMany = 30\n",
    "files = [f for f in os.listdir(picturesFolder) if os.path.isfile(os.path.join(picturesFolder, f))]\n",
    "\n",
    "if onAll:\n",
    "    predictables = np.array(process_image_files([os.path.join(picturesFolder, pic) for pic in files]))\n",
    "else:\n",
    "    predictables = np.array(process_image_files([os.path.join(picturesFolder, pic) for pic in files[:howMany]]))\n",
    "\n",
    "predicted = [prediction[0] for prediction in [classifier.predict(p.reshape(1,-1)) for p in predictables]]\n",
    "\n",
    "if onAll:\n",
    "    classification = zip(files, predicted)\n",
    "else:\n",
    "    classification = zip(files[:howMany], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store classification\n",
    "\n",
    "savePath = './'\n",
    "\n",
    "with open(os.path.join(savePath, 'classifiedFood.csv'), 'wb') as out:\n",
    "    csv_out=csv.writer(out)\n",
    "    csv_out.writerow(['filename','food'])\n",
    "    for row in classification:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
