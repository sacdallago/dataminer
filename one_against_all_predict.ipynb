{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import utils as ut\n",
    "import gc\n",
    "import csv\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from os import listdir\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data dir\n",
    "imagesDir = './data/SampleFoodClassifier_Norm_100'\n",
    "\n",
    "# Get list of files\n",
    "files = [f for f in listdir(imagesDir) if path.isfile(path.join(imagesDir, f))]\n",
    "predictions = [{'id': element} for element in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 100, 100, 3], name=\"x\")\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "sdev= 0.01\n",
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# Layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.truncated_normal([5, 5, 3, 32], stddev=sdev), name=\"wc1\"),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=sdev), name=\"wc2\"),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.truncated_normal([25*25*64, 1024], stddev=sdev), name=\"wd1\"),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.truncated_normal([1024, 2], stddev=sdev), name=\"outw\")\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.truncated_normal([32], stddev=sdev), name=\"bc1\"),\n",
    "    'bc2': tf.Variable(tf.truncated_normal([64], stddev=sdev), name=\"bc2\"),\n",
    "    'bd1': tf.Variable(tf.truncated_normal([1024], stddev=sdev), name=\"bd1\"),\n",
    "    'out': tf.Variable(tf.truncated_normal([2], stddev=sdev, name=\"outd\"))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "classes = tf.nn.softmax(pred)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the models\n",
    "saveDir = './tensorflow/one_against_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(files):\n",
    "    return [np.array(Image.open(path.join(imagesDir, element))) for element in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for currentLabel in range(9):\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print \"Running predictions for label\", currentLabel\n",
    "    \n",
    "    class_pred = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, path.join(saveDir, \"label-\" + str(currentLabel) + \".ckpt\"))\n",
    "        \n",
    "        for i in range(0, len(files), 50):\n",
    "            if i+50 > len(files):\n",
    "                data = loadData(files[i:])\n",
    "            else:\n",
    "                data = loadData(files[i:i+50])\n",
    "            cls = sess.run(classes, feed_dict={x: data, keep_prob: 1.})\n",
    "            class_pred.extend(cls)\n",
    "    \n",
    "    for i in range(len(files)):\n",
    "        predictions[i][str(currentLabel)] = class_pred[i][1]\n",
    "\n",
    "keys = predictions[0].keys()\n",
    "with open(path.join('predictions','one_vs_all_class_prediction.csv'), 'wb') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
